{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEFxqUENqpn3"
      },
      "outputs": [],
      "source": [
        "1. Write Python scripts for basic file operations and data processing?\n",
        "\n",
        "# file_operations.py\n",
        "# This script demonstrates basic file handling: writing, reading, and appending.\n",
        "\n",
        "# --- 1. Define the filename ---\n",
        "# We'll use this variable to refer to our file.\n",
        "filename = \"sample.txt\"\n",
        "\n",
        "# --- 2. Write to a file ---\n",
        "# The 'w' mode opens the file for writing.\n",
        "# If the file already exists, its contents are deleted. If not, it's created.\n",
        "print(f\"--- Writing to {filename} ---\")\n",
        "try:\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"Hello, World!\\n\")\n",
        "        f.write(\"This is the first line of the file.\\n\")\n",
        "        f.write(\"Writing files in Python is straightforward.\\n\")\n",
        "    print(f\"Successfully wrote initial content to {filename}\")\n",
        "except IOError as e:\n",
        "    print(f\"Error writing to file: {e}\")\n",
        "\n",
        "# --- 3. Read from a file ---\n",
        "# The 'r' mode opens the file for reading. This is the default mode.\n",
        "print(f\"\\n--- Reading from {filename} ---\")\n",
        "try:\n",
        "    with open(filename, 'r') as f:\n",
        "        # .read() reads the entire content of the file into a string\n",
        "        content = f.read()\n",
        "        print(\"Full content of the file:\")\n",
        "        print(content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {filename} was not found.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error reading file: {e}\")\n",
        "\n",
        "# --- 4. Append to a file ---\n",
        "# The 'a' mode opens the file for appending.\n",
        "# New content is added to the end of the file without deleting existing content.\n",
        "print(f\"\\n--- Appending to {filename} ---\")\n",
        "try:\n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(\"\\nThis line was appended to the file.\\n\")\n",
        "        f.write(\"Appending is useful for logging or adding new records.\\n\")\n",
        "    print(f\"Successfully appended content to {filename}\")\n",
        "except IOError as e:\n",
        "    print(f\"Error appending to file: {e}\")\n",
        "\n",
        "# --- 5. Read the file again to see the appended content ---\n",
        "print(f\"\\n--- Reading {filename} after appending ---\")\n",
        "try:\n",
        "    with open(filename, 'r') as f:\n",
        "        # We can also read a file line by line\n",
        "        print(\"Content of the file line-by-line:\")\n",
        "        for line in f:\n",
        "            print(line.strip()) # .strip() removes leading/trailing whitespace\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {filename} was not found.\")\n",
        "except IOError as e:\n",
        "    print(f\"Error reading file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2. Develop a simple web scraper to extract data from a website?\n",
        "# web_scraper.py\n",
        "# This script demonstrates a simple web scraper that extracts data from a website.\n",
        "# It uses the 'requests' library to fetch the webpage and 'BeautifulSoup' to parse it.\n",
        "\n",
        "# Make sure you have the required libraries installed:\n",
        "# pip install requests\n",
        "# pip install beautifulsoup4\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# --- 1. Define the target URL ---\n",
        "# We will scrape quotes from this website.\n",
        "URL = 'http://quotes.toscrape.com/'\n",
        "\n",
        "print(f\"--- Scraping data from: {URL} ---\")\n",
        "\n",
        "# --- 2. Fetch the webpage content ---\n",
        "# It's good practice to wrap network requests in a try-except block\n",
        "# to handle potential connection errors, timeouts, etc.\n",
        "try:\n",
        "    # The 'get' method sends a request to the URL.\n",
        "    response = requests.get(URL)\n",
        "\n",
        "    # This will raise an HTTPError if the HTTP request returned an unsuccessful status code.\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Get the HTML content from the response.\n",
        "    html_content = response.text\n",
        "\n",
        "    # --- 3. Parse the HTML with BeautifulSoup ---\n",
        "    # BeautifulSoup allows us to navigate and search the parsed HTML tree.\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # --- 4. Find and extract the desired data ---\n",
        "    # We inspect the website's HTML to find the right tags and classes.\n",
        "    # On quotes.toscrape.com, each quote is within a <div class=\"quote\">.\n",
        "    quotes_divs = soup.find_all('div', class_='quote')\n",
        "\n",
        "    if not quotes_divs:\n",
        "        print(\"No quotes found on the page. The website structure might have changed.\")\n",
        "    else:\n",
        "        print(f\"Found {len(quotes_divs)} quotes. Extracting...\\n\")\n",
        "        # Loop through each quote container we found\n",
        "        for i, quote_div in enumerate(quotes_divs):\n",
        "            # The quote text is in a <span class=\"text\">\n",
        "            text_span = quote_div.find('span', class_='text')\n",
        "            # The author is in a <small class=\"author\">\n",
        "            author_small = quote_div.find('small', class_='author')\n",
        "\n",
        "            if text_span and author_small:\n",
        "                # .text extracts the text content from the tag\n",
        "                quote_text = text_span.text\n",
        "                author_name = author_small.text\n",
        "                print(f\"Quote {i+1}:\")\n",
        "                print(f'\"{quote_text}\"')\n",
        "                print(f\"- {author_name}\\n\")\n",
        "            else:\n",
        "                print(f\"Could not extract full details for a quote entry.\")\n",
        "\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    # This catches any network-related errors (DNS failure, refused connection, etc).\n",
        "    print(f\"An error occurred while trying to fetch the website: {e}\")\n",
        "except Exception as e:\n",
        "    # A general exception for any other unforeseen errors.\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "hyjKhZyGrTip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}